# 综合练习：数据管道处理系统

## 项目简介

本综合练习需要你运用迭代器的知识，实现一个数据管道处理系统。该系统支持链式处理、数据转换、过滤、聚合等操作，并实现自定义迭代器。

## 项目需求

### 功能描述

创建一个数据管道系统，支持：
1. 多种数据源（向量、数组、范围、自定义迭代器）
2. 链式数据处理操作
3. 灵活的过滤和转换
4. 高效的聚合操作
5. 自定义迭代器生成器

### 核心数据结构

#### 1. 管道类型

```rust
enum DataSource<'a, T> {
    Vec(&'a Vec<T>),
    Slice(&'a [T]),
    Range(Range<T>),
    Custom(Box<dyn Iterator<Item = T> + 'a>),
}
```

#### 2. 管道配置

```rust
struct PipelineConfig {
    filter_threshold: Option<usize>,
    transform_func: Option<Box<dyn Fn(usize) -> usize>>,
    batch_size: usize,
}
```

#### 3. 管道结果

```rust
enum PipelineResult<T, E> {
    Success(T),
    Error(E),
}

struct PipelineStats {
    processed: usize,
    filtered: usize,
    transformed: usize,
    duration_ms: u128,
}
```

#### 4. 数据管道

```rust
struct DataPipeline<'a, T> {
    source: DataSource<'a, T>,
    config: PipelineConfig,
    stats: PipelineStats,
}
```

### 必须实现的功能

#### DataSource 方法

1. `new_vec(data: &'a Vec<T>) -> Self`
   - 创建向量数据源

2. `new_slice(data: &'a [T]) -> Self`
   - 创建切片数据源

3. `new_range(range: Range<T>) -> Self`
   - 创建范围数据源

4. `new_custom(iter: Box<dyn Iterator<Item = T> + 'a>) -> Self`
   - 创建自定义迭代器数据源

#### DataPipeline 方法

5. `new(source: DataSource<'a, T>, config: PipelineConfig) -> Self`
   - 创建新的数据管道

6. `process<F>(&self, func: F) -> Vec<F::Output> where
    F: Fn(usize) -> F::Output
   - 处理所有数据元素

7. `filter<P>(&self, predicate: P) -> Vec<usize> where
    P: Fn(&usize) -> bool
   - 过滤数据元素

8. `transform<F>(&self, func: F) -> Vec<usize> where
    F: Fn(usize) -> usize
   - 转换每个数据元素

9. `aggregate(&self) -> (usize, usize, usize, usize)
   - 返回 (count, sum, min, max)

10. `batch_process(&self, batch_size: usize) -> Vec<Vec<usize>>`
    - 将数据分批处理

11. `with_stats<F>(&mut self, func: F) -> PipelineResult<Vec<usize>, String> where
    F: FnMut(&mut DataPipeline<'a, T>) -> ()
    - 执行操作并记录统计

#### PipelineStats 方法

12. `new() -> Self`
    - 创建空的统计

13. `record_processed(&mut self, count: usize)`
    - 记录处理的元素数量

14. `record_filtered(&mut self, count: usize)`
    - 记录过滤的元素数量

15. `record_transformed(&mut self, count: usize)`
    - 记录转换的元素数量

16. `reset(&mut self)`
    - 重置统计信息

### 使用示例

```rust
use module_12_iterators::pipeline::*;

fn main() {
    // 创建配置
    let config = PipelineConfig {
        filter_threshold: Some(5),
        transform_func: Some(Box::new(|x| x * 2)),
        batch_size: 3,
    };

    // 创建数据源
    let data: Vec<usize> = (1..=10).collect();
    let source = DataSource::new_vec(&data);

    // 创建管道
    let mut pipeline = DataPipeline::new(source, config);

    // 处理数据
    let result = pipeline.process(|x| {
        println!("处理: {}", x);
        x + 1
    });
    println!("处理结果: {:?}", result);

    // 过滤数据
    let filtered = pipeline.filter(|&x| x % 2 == 0);
    println!("过滤结果: {:?}", filtered);

    // 转换数据
    let transformed = pipeline.transform(|x| x * 3);
    println!("转换结果: {:?}", transformed);

    // 聚合统计
    let (count, sum, min, max) = pipeline.aggregate();
    println!("统计: count={}, sum={}, min={}, max={}", count, sum, min, max);

    // 分批处理
    let batches = pipeline.batch_process(3);
    println!("批次: {:?}", batches);

    // 带统计处理
    let final_result = pipeline.with_stats(|p| {
        // 在这里执行所有操作
    });

    match final_result {
        PipelineResult::Success(data) => println!("成功: {:?}", data),
        PipelineResult::Error(e) => println!("错误: {}", e),
    }
}
```

## 验收标准

### 功能要求

- [ ] 支持 4 种数据源类型
- [ ] 实现 10 个核心管道方法
- [ ] 实现 4 个统计方法
- [ ] 支持链式操作
- [ ] 错误处理完善

### 代码质量

- [ ] 所有单元测试通过
- [ ] 代码通过 `cargo clippy` 检查
- [ ] 代码格式化 `cargo fmt`
- [ ] 有适当的文档注释
- [ ] 使用高效的迭代器操作

### 性能考虑

- [ ] 避免不必要的克隆
- [ ] 合理使用迭代器适配器
- [ ] 支持惰性求值
- [ ] 内存使用高效

## 实现步骤

1. **创建文件结构**：
   ```bash
   mkdir -p src/pipeline
   touch src/pipeline/mod.rs
   touch src/pipeline/source.rs
   touch src/pipeline/pipeline.rs
   touch src/pipeline/stats.rs
   ```

2. **实现 DataSource**：
   - 定义枚举变体
   - 实现创建方法
   - 实现 Iterator trait

3. **实现 PipelineConfig**：
   - 定义配置结构体
   - 提供默认配置

4. **实现 DataPipeline**：
   - 实现所有管道方法
   - 使用迭代器适配器
   - 支持链式调用

5. **实现 PipelineStats**：
   - 定义统计结构体
   - 实现记录方法
   - 提供格式化输出

6. **编写测试**：
   - 单元测试
   - 集成测试
   - 性能测试

7. **运行验证**：
   ```bash
   cargo test -p module-12-iterators
   cargo clippy -p module-12-iterators
   cargo fmt -p module-12-iterators
   ```

## 测试用例

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_vec_source() {
        let data = vec
![1, 2, 3, 4, 5];
        let source = DataSource::new_vec(&data);
        let mut pipeline = DataPipeline::new(source, PipelineConfig::default());
        let result = pipeline.process(|x| x * 2);
        assert_eq!(result, vec
![2, 4, 6, 8, 10]);
    }

    #[test]
    fn test_filter() {
        let data: Vec<usize> = (1..=10).collect();
        let source = DataSource::new_vec(&data);
        let config = PipelineConfig {
            filter_threshold: Some(5),
            ..Default::default()
        };
        let pipeline = DataPipeline::new(source, config);
        let filtered = pipeline.filter(|&x| x <= 5);
        assert_eq!(filtered, vec
![1, 2, 3, 4, 5]);
    }

    #[test]
    fn test_transform() {
        let data = vec
![1, 2, 3];
        let source = DataSource::new_vec(&data);
        let mut pipeline = DataPipeline::new(source, PipelineConfig::default());
        let transformed = pipeline.transform(|x| x * 3);
        assert_eq!(transformed, vec
![3, 6, 9]);
    }

    #[test]
    fn test_aggregate() {
        let data = vec
![1, 2, 3, 4, 5];
        let source = DataSource::new_vec(&data);
        let pipeline = DataPipeline::new(source, PipelineConfig::default());
        let (count, sum, min, max) = pipeline.aggregate();
        assert_eq!(count, 5);
        assert_eq!(sum, 15);
        assert_eq!(min, 1);
        assert_eq!(max, 5);
    }

    #[test]
    fn test_batch_process() {
        let data: Vec<usize> = (1..=10).collect();
        let source = DataSource::new_vec(&data);
        let pipeline = DataPipeline::new(source, PipelineConfig::default());
        let batches = pipeline.batch_process(3);
        assert_eq!(batches.len(), 4);
        assert_eq!(batches[0], vec
![1, 2, 3]);
        assert_eq!(batches[1], vec
![4, 5, 6]);
        assert_eq!(batches[2], vec
![7, 8, 9]);
        assert_eq!(batches[3], vec
![10]);
    }

    #[test]
    fn test_range_source() {
        let source = DataSource::new_range(1..=5);
        let mut pipeline = DataPipeline::new(source, PipelineConfig::default());
        let result = pipeline.process(|x| x * x);
        assert_eq!(result, vec
![1, 4, 9, 16, 25]);
    }

    #[test]
    fn test_custom_iterator() {
        struct Counter {
            count: u32,
        }
        impl Counter {
            fn new() -> Self {
                Counter { count: 0 }
            }
        }
        impl Iterator for Counter {
            type Item = usize;
            fn next(&mut self) -> Option<Self::Item> {
                self.count += 1;
                if self.count <= 5 {
                    Some(self.count as usize)
                } else {
                    None
                }
            }
        }

        let source = DataSource::new_custom(Box::new(Counter::new()));
        let pipeline = DataPipeline::new(source, PipelineConfig::default());
        let result = pipeline.process(|x| x);
        assert_eq!(result, vec
![1, 2, 3, 4, 5]);
    }

    #[test]
    fn test_stats_tracking() {
        let data = vec
![1, 2, 3, 4, 5];
        let source = DataSource::new_vec(&data);
        let mut pipeline = DataPipeline::new(source, PipelineConfig::default());

        let _ = pipeline.filter(|_| true);
        assert_eq!(pipeline.stats.processed, 5);
    }

    #[test]
    fn test_chain_operations() {
        let data: Vec<usize> = (1..=10).collect();
        let source = DataSource::new_vec(&data);
        let mut pipeline = DataPipeline::new(source, PipelineConfig::default());

        let result: Vec<usize> = data.iter()
            .filter(|&&x| x % 2 == 0)
            .map(|&x| x * 2)
            .filter(|&&x| x > 4)
            .take(3)
            .copied()
            .collect();

        assert_eq!(result, vec
![4, 8, 12]);
    }
}
```

## 扩展挑战（可选）

完成基础要求后，可以尝试以下扩展：

1. **并行处理**：
   - 使用 Rayon 实现并行迭代器
   - 支持并行 map 和 filter

2. **流式处理**：
   - 支持无限数据源
   - 实现窗口函数
   - 支持 join 操作

3. **错误传播**：
   - 支持 Result 类型的迭代器
   - 实现收集所有错误的机制
   - 提供详细的错误信息

4. **内存优化**：
   - 支持零拷贝操作
   - 实现惰性评估
   - 支持外部迭代器

5. **自定义适配器**：
   - 实现自定义迭代器适配器
   - 支持组合多个适配器
   - 实现高效的聚合函数

## 提示

<details>
<summary>Iterator 实现提示</summary>

```rust
impl<'a, T> Iterator for DataSource<'a, T> {
    type Item = T;

    fn next(&mut self) -> Option<Self::Item> {
        match self {
            DataSource::Vec(vec) => {
                // 需要额外状态跟踪当前位置
            }
            DataSource::Slice(slice) => {
                // 需要额外状态跟踪当前位置
            }
            DataSource::Range(range) => {
                range.next()
            }
            DataSource::Custom(iter) => {
                iter.next()
            }
        }
    }
}
```

- Vec 和 Slice 需要额外的状态来跟踪当前迭代位置
- Range 可以直接使用内置迭代器
- Custom 直接委托给内部迭代器
</details>

<details>
<summary>链式操作提示</summary>

```rust
fn chain_operations(&self) -> Vec<usize> {
    // 使用迭代器链实现复杂的处理流程
    let result: Vec<usize> = self.source.iter()
        .filter(|&x| x % 2 == 0)
        .map(|x| x * 2)
        .filter(|&x| x > 10)
        .take(5)
        .collect();

    result
}
```

- 迭代器链是惰性的，不会立即计算
- 每个 adapter 都返回一个新的迭代器
- 只有在 collect() 或其他 consumer 时才会实际计算
</details>

<details>
<summary>性能优化提示</summary>

- 使用 `.copied()` 而不是 `.map(|&x| x)` 实现了 Copy 的类型
- 使用 `.cloned()` 而不是 `.map(|x| x.clone())` 需要 Clone 的类型
- 尽可能使用迭代器而不是索引访问
- 避免在循环中重复创建 Vec
- 使用 `fold()` 而不是手动累积
</details>

## 学习目标

通过本项目，你将：

1. **掌握 Iterator trait**：
   - 实现 Iterator trait
   - 理解关联类型
   - 理解 next() 方法

2. **熟练使用迭代器适配器**：
   - map, filter, fold 等
   - 链式调用
   - 组合使用

3. **理解惰性求值**：
   - 迭代器的惰性特性
   - 性能优势
   - 避免不必要的计算

4. **实现自定义迭代器**：
   - 创建自定义数据源
   - 实现复杂的迭代逻辑
   - 支持所有迭代器方法

5. **设计数据管道**：
   - 链式数据处理
   - 可配置的管道
   - 高效的数据转换

## 参考实现

完成项目后，可以查看 `solutions/pipeline.rs` 中的参考实现。
